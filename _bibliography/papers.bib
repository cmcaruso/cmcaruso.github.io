---
---

@article{caruso2022multimodal,
  abbr={MDPI},
  title={{A Multimodal Ensemble Driven by Multiobjective Optimisation to Predict Overall Survival in Non-Small-Cell Lung Cancer}},
  author={Caruso, Camillo Maria and Guarrasi, Valerio and Cordelli, Ermanno and Sicilia, Rosa and Gentile, Silvia and Messina, Laura and Fiore, Michele and Piccolo, Claudia and Beomonte Zobel, Bruno and Iannello, Giulio and others},
  journal={Journal of Imaging},
  volume={8},
  number={11},
  pages={298},
  year={2022},
  doi={10.3390/jimaging8110298},
  url={https://www.mdpi.com/2313-433X/8/11/298},
  publisher={MDPI},
  abstract={Lung cancer accounts for more deaths worldwide than any other cancer disease. In order to provide patients with the most effective treatment for these aggressive tumours, multimodal learning is emerging as a new and promising field of research that aims to extract complementary information from the data of different modalities for prognostic and predictive purposes. This knowledge could be used to optimise current treatments and maximise their effectiveness. To predict overall survival, in this work, we investigate the use of multimodal learning on the CLARO dataset, which includes CT images and clinical data collected from a cohort of non-small-cell lung cancer patients. Our method allows the identification of the optimal set of classifiers to be included in the ensemble in a late fusion approach. Specifically, after training unimodal models on each modality, it selects the best ensemble by solving a multiobjective optimisation problem that maximises both the recognition performance and the diversity of the predictions. In the ensemble, the labels of each sample are assigned using the majority voting rule. As further validation, we show that the proposed ensemble outperforms the models learning a single modality, obtaining state-of-the-art results on the task at hand.}
}

@inproceedings{guarrasi2023building,
  abbr={Ital-IA 2023},
  title={{Building an AI-Enabled Metaverse for Intelligent Healthcare: Opportunities and Challenges}},
  author={Guarrasi, Valerio and Tronchin, Lorenzo and Caruso, Camillo Maria and Rofena, Aurora and Manni, Guido and Aksu, Fatih and Paolo, Domenico and Iannello, Giulio and Sicilia, Rosa and Cordelli, Ermanno and others},
  booktitle={CEUR WORKSHOP PROCEEDINGS},
  volume={3486},
  pages={134--139},
  html = {https://hdl.handle.net/20.500.12610/79228},
  year={2023},
  abstract={This abstract discusses the development of a metaverse for intelligent healthcare, which involves creating a virtual environment where healthcare professionals, patients, and researchers can interact and collaborate using digital technologies. The metaverse can improve the efficiency and effectiveness of healthcare services and provide new opportunities for research and innovation. AI models are necessary for analyzing patient data and providing personalized healthcare recommendations, but the data in a metaverse setting is inherently multimodal, unstructured, noisy, incomplete, limited, or partially inconsistent, which poses a challenge for AI models. However, it becomes necessary the integration of AI models for the development of virtual scanners to simulate image modalities, and robotics to simulate surgical procedures within a virtual environment. The ultimate goal is to leverage the power of AI to enhance the quality of healthcare in a metaverse for intelligent healthcare, which has the potential to transform the way healthcare services are delivered and improve health outcomes for patients worldwide.}
}

@article{caruso2023cascade,
  abbr={IEEE Access},
  title={{A Cascade of Learners for Firemen’ Emergency Events Classification}},
  author={Caruso, Camillo Maria and Soda, Paolo and Giammichele, Carlo and Rotilio, Francesca and Sicilia, Rosa},
  journal={IEEE Access},
  volume={11},
  pages={122399--122410},
  year={2023},
  publisher={IEEE}
}

@article{caruso2024deep,
  abbr={CMPB},
  title={A Deep Learning Approach for Overall Survival Prediction in Lung Cancer with Missing Values},
  author={Caruso, Camillo Maria and Guarrasi, Valerio and Ramella, Sara and Soda, Paolo},
  journal={Computer Methods and Programs in Biomedicine},
  volume={254},
  pages={108308},
  year={2024},
  doi={10.1016/j.cmpb.2024.108308},
  url={https://www.sciencedirect.com/science/article/pii/S016926072400302X},
  code={https://github.com/cosbidev/OSTransformer},
  publisher={Elsevier},
  abstract={
    Background and Objective:
    In the field of lung cancer research, particularly in the analysis of overall survival (OS), artificial intelligence (AI) serves crucial roles with specific aims. Given the prevalent issue of missing data in the medical domain, our primary objective is to develop an AI model capable of dynamically handling this missing data. Additionally, we aim to leverage all accessible data, effectively analyzing both uncensored patients who have experienced the event of interest and censored patients who have not, by embedding a specialized technique within our AI model, not commonly utilized in other AI tasks. Through the realization of these objectives, our model aims to provide precise OS predictions for non-small cell lung cancer (NSCLC) patients, thus overcoming these significant challenges.
    Methods:
    We present a novel approach to survival analysis with missing values in the context of NSCLC, which exploits the strengths of the transformer architecture to account only for available features without requiring any imputation strategy. More specifically, this model tailors the transformer architecture to tabular data by adapting its feature embedding and masked self-attention to mask missing data and fully exploit the available ones. By making use of ad-hoc designed losses for OS, it is able to account for both censored and uncensored patients, as well as changes in risks over time.
    Results:
    We compared our method with state-of-the-art models for survival analysis coupled with different imputation strategies. We evaluated the results obtained over a period of 6 years using different time granularities obtaining a Ct-index, a time-dependent variant of the C-index, of 71.97, 77.58 and 80.72 for time units of 1 month, 1 year and 2 years, respectively, outperforming all state-of-the-art methods regardless of the imputation method used.
    Conclusions:
    The results show that our model not only outperforms the state-of-the-art’s performance but also simplifies the analysis in the presence of missing data, by effectively eliminating the need to identify the most appropriate imputation strategy for predicting OS in NSCLC patients.}
}

@article{caruso2024not,
  abbr={arXiv},
  title={Not Another Imputation Method: A Transformer-based Model for Missing Values in Tabular Datasets},
  author={Caruso, Camillo Maria and Soda, Paolo and Guarrasi, Valerio},
  journal={arXiv preprint arXiv:2407.11540},
  code={https://github.com/cosbidev/NAIM},
  arxiv={2407.11540},
  year={2024},
  selected={true},
  abstract={Handling missing values in tabular datasets presents a significant challenge in training and testing artificial intelligence models, an issue usually addressed using imputation techniques. Here we introduce "Not Another Imputation Method" (NAIM), a novel transformer-based model specifically designed to address this issue without the need for traditional imputation techniques. NAIM's ability to avoid the necessity of imputing missing values and to effectively learn from available data relies on two main techniques: the use of feature-specific embeddings to encode both categorical and numerical features also handling missing inputs; the modification of the masked self-attention mechanism to completely mask out the contributions of missing data. Additionally, a novel regularization technique is introduced to enhance the model's generalization capability from incomplete data. We extensively evaluated NAIM on 5 publicly available tabular datasets, demonstrating its superior performance over 6 state-of-the-art machine learning models and 5 deep learning models, each paired with 3 different imputation techniques when necessary. The results highlight the efficacy of NAIM in improving predictive performance and resilience in the presence of missing data. To facilitate further research and practical application in handling missing data without traditional imputation methods, we made the code for NAIM available at https://github.com/cosbidev/NAIM.}
}

@article{guarrasi2025systematic,
  abbr={IMAVIS},
  title={A systematic review of intermediate fusion in multimodal deep learning for biomedical applications},
  author={Guarrasi, Valerio and Aksu, Fatih and Caruso, Camillo Maria and Di Feola, Francesco and Rofena, Aurora and Ruffini, Filippo and Soda, Paolo},
  journal={Image and Vision Computing},
  pages={105509},
  year={2025},
  url={https://www.sciencedirect.com/science/article/pii/S0262885625000976},
  doi={10.1016/j.imavis.2025.105509},
  supp={https://ars.els-cdn.com/content/image/1-s2.0-S0262885625000976-mmc2.pdf},
  publisher={Elsevier},
  abstract={Deep learning has revolutionized biomedical research by providing sophisticated methods to handle complex, high-dimensional data. Multimodal deep learning (MDL) further enhances this capability by integrating diverse data types such as imaging, textual data, and genetic information, leading to more robust and accurate predictive models. In MDL, differently from early and late fusion methods, intermediate fusion stands out for its ability to effectively combine modality-specific features during the learning process. This systematic review comprehensively analyzes and formalizes current intermediate fusion methods in biomedical applications, highlighting their effectiveness in improving predictive performance and capturing complex inter-modal relationships. We investigate the techniques employed, the challenges faced, and potential future directions for advancing intermediate fusion methods. Additionally, we introduce a novel structured notation that standardizes intermediate fusion architectures, enhancing understanding and facilitating implementation across various domains. Our findings provide actionable insights and practical guidelines intended to support researchers, healthcare professionals, and the broader deep learning community in developing more sophisticated and insightful multimodal models. Through this review, we aim to provide a foundational framework for future research and practical applications in the dynamic field of MDL.}
}

@inproceedings{aksu2024towards,
  abbr={Ital-IA 2024},
  title={Towards AI-driven next generation personalized healthcare and well-being},
  author={Aksu, Fatih and Bria, Alessandro and Caragliano, Alice Natalina and Caruso, Camillo Maria and Chen, Wenting and Cordelli, Ermanno and Coser, Omar and Francesconi, Arianna and Furia, Leonardo and Guarrasi, Valerio and others},
  booktitle={2024 Ital-IA Intelligenza Artificiale-Thematic Workshops, Ital-IA 2024, Naples, Italy, May 29-30, 2024},
  pages={360--365},
  year={2024},
  html={https://hdl.handle.net/20.500.12610/82624},
  organization={CEUR-WS},
  abstract={In the last few years Artificial Intelligence (AI) is emerging as a game changer in many areas of society and, in particular, its integration in medicine heralds a transformative approach towards personalized healthcare and well-being, promising significant improvements in diagnostic precision, therapeutic outcomes, and patient care. Our research explores the cuttingedge realms of multimodal AI, resilient AI, and healthcare robotics, aiming to harness the synergy of diverse data modalities and advanced computational models to redefine healthcare paradigms. This multidisciplinary effort seeks to bridge technology and clinical practice, advancing AI-driven next generation personalized healthcare and well-being.}
}

@article{caruso2024maria,
  abbr={arXiv},
  title={MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data},
  author={Caruso, Camillo Maria and Soda, Paolo and Guarrasi, Valerio},
  journal={arXiv preprint arXiv:2412.14810},
  arxiv={2412.14810},
  year={2024},
  abstract={In healthcare, the integration of multimodal data is pivotal for developing comprehensive diagnostic and predictive models. However, managing missing data remains a significant challenge in real-world applications. We introduce MARIA (Multimodal Attention Resilient to Incomplete datA), a novel transformer-based deep learning model designed to address these challenges through an intermediate fusion strategy. Unlike conventional approaches that depend on imputation, MARIA utilizes a masked self-attention mechanism, which processes only the available data without generating synthetic values. This approach enables it to effectively handle incomplete datasets, enhancing robustness and minimizing biases introduced by imputation methods. We evaluated MARIA against 10 state-of-the-art machine learning and deep learning models across 8 diagnostic and prognostic tasks. The results demonstrate that MARIA outperforms existing methods in terms of performance and resilience to varying levels of data incompleteness, underscoring its potential for critical healthcare applications.}
}
